{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "#from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "\n",
    "INPUT_DIR_PATH = '/Users/salvo/Documents/tesi/datasets/snippets_2000_47_score-2_acc-false_rows-2/'\n",
    "\n",
    "languages = []\n",
    "for lang in os.listdir(INPUT_DIR_PATH):\n",
    "    languages.append(lang)\n",
    "\n",
    "snippets_dic = {}\n",
    "for lang in languages:\n",
    "    files = glob.glob(INPUT_DIR_PATH + lang.lower() + '/*txt')\n",
    "    print('current lang: ' + lang + ', files:' + str(len(files)))\n",
    "\n",
    "    cur_snippets = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf8') as file:\n",
    "            cur_snippets.append(file.read())\n",
    "\n",
    "    snippets_dic[lang] = cur_snippets\n",
    "\n",
    "snippets = pd.DataFrame(snippets_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pattern = r'''[\\w']+|[\"\"!\"#$%&'()*+,-./:;<=>?@\\[\\]^_`{|}~\"\"]'''\n",
    "\n",
    "def tokenize(snippet):\n",
    "\n",
    "    temp = re.sub(r'\".*\"|\\'.*\\'', 'strv', snippet)\n",
    "    return regexp_tokenize(temp, pattern)\n",
    "    # return word_tokenize(temp)\n",
    "\n",
    "snippets = snippets.applymap(tokenize)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "snippets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "list_data = []\n",
    "for lang in languages:\n",
    "    list_data = list_data + snippets[lang].tolist()\n",
    "\n",
    "w2v_model = Word2Vec(list_data, size=300, min_count=5)\n",
    "\n",
    "words = list(w2v_model.wv.vocab)\n",
    "w2v_model.save('../models/w2v_model.bin')\n",
    "\n",
    "#w2v_model.wv.vocab[word].index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec.load('../models/w2v_model.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_similar_to = 'print'\n",
    "\n",
    "print('Similar words to '+find_similar_to+': \\n')\n",
    "\n",
    "# Find similar words, using cosine similarity\n",
    "# by default shows top 10 similar words\n",
    "for similar_word in w2v_model.wv.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.3f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w2v_model.wv['print']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}